{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63d9ac2-89bb-4e0e-b887-00073a18d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88edf8f-bf97-4552-aced-9699f6b78329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf25781-d454-4ef7-87fd-115c45a9cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feet_inches_to_inches(string):\n",
    "    split = string.split('ft')\n",
    "    feet = split[0].strip()\n",
    "    inches = split[1].strip()\n",
    "    inches = inches.split('in')\n",
    "    inches = inches[0].strip()\n",
    "    return 12 * int(feet) + int(inches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614e2f3c-67a8-4cd9-bc21-8d6a9f57d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_time_and_group_size(user, location):\n",
    "    if location.endswith('.'):\n",
    "        location = location[:-1]  # Remove the period.\n",
    "    match location:\n",
    "        case \"Bar / Nightclub\":\n",
    "            return user.bar_day_of_week, user.bar_time_of_day, user.bar_group_size\n",
    "        case \"Sit-down restaurant\":\n",
    "            return user.restaurant_day_of_week, user.restaurant_time_of_day, user.restaurant_group_size\n",
    "        case \"University\":\n",
    "            return user.university_day_of_week, user.university_time_of_day, user.university_group_size\n",
    "        case \"School / University\":\n",
    "            return user.university_day_of_week, user.university_time_of_day, user.university_group_size\n",
    "        case \"Workplace\":\n",
    "            return user.workplace_day_of_week, user.workplace_time_of_day, user.workplace_group_size\n",
    "        case \"Community event (block-party, social club, hangout, potluck, etc.)\":\n",
    "            return user.community_day_of_week, user.community_time_of_day, user.community_group_size\n",
    "        case \"Cafe / Coffee shop\":\n",
    "            return user.cafe_day_of_week, user.cafe_time_of_day, user.cafe_group_size\n",
    "        case \"Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)\":\n",
    "            return user.attraction_day_of_week, user.attraction_time_of_day, user.attraction_group_size\n",
    "        case \"Outdoor activity (walking/hiking trail, biking, park, neighborhood, dog park, etc.)\":\n",
    "            return user.outdoor_day_of_week, user.outdoor_time_of_day, user.outdoor_group_size\n",
    "        case \"Gym\":\n",
    "            return user.gym_day_of_week, user.gym_time_of_day, user.gym_group_size\n",
    "        case _:\n",
    "            raise Exception(\"Invalid location.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2eb8d4-7ff2-428f-ba8a-72836df35af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_clothing_list(clothing_list):\n",
    "    result = []\n",
    "    for clothing in clothing_list:\n",
    "        cloth = clothing\n",
    "        if cloth.endswith('.'):\n",
    "            cloth = cloth[:-1]  # Remove the period.\n",
    "        cloth = cloth.lower()\n",
    "        result.append(cloth)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a4d03a-2279-4403-96bd-26f30625e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_clothing(clothing_str, user, location):\n",
    "    clothing_str = clothing_str.lower()\n",
    "    if clothing_str.endswith('.'):\n",
    "        clothing_str = clothing_str[:-1]  # Remove the period.\n",
    "    if clothing_str not in ['athletic clothes', 'casual clothes', 'trendy clothes', 'formal clothes', 'designer clothes', 'hat', 'eyeglasses', 'sunglasses', 'necklace', 'luxury watch', 'rings', 'earrings', 'smart watch']:\n",
    "        raise Exception(\"Invalid clothing.\")\n",
    "    if location.endswith('.'):\n",
    "        location = location[:-1]  # Remove the period.\n",
    "    match location:\n",
    "        case \"Bar / Nightclub\":\n",
    "            return clothing_str in clean_clothing_list(user.bar_clothing)\n",
    "        case \"Sit-down restaurant\":\n",
    "            return clothing_str in clean_clothing_list(user.restaurant_clothing)\n",
    "        case \"University\":\n",
    "            return clothing_str in clean_clothing_list(user.university_clothing)\n",
    "        case \"School / University\":\n",
    "            return clothing_str in clean_clothing_list(user.university_clothing)\n",
    "        case \"Workplace\":\n",
    "            return clothing_str in clean_clothing_list(user.workplace_clothing)\n",
    "        case \"Community event (block-party, social club, hangout, potluck, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.community_clothing)\n",
    "        case \"Cafe / Coffee shop\":\n",
    "            return clothing_str in clean_clothing_list(user.cafe_clothing)\n",
    "        case \"Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.attraction_clothing)\n",
    "        case \"Outdoor activity (walking/hiking trail, biking, park, neighborhood, dog park, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.outdoor_clothing)\n",
    "        case \"Gym\":\n",
    "            return clothing_str in clean_clothing_list(user.gym_clothing)\n",
    "        case _:\n",
    "            raise Exception(\"Invalid location (when checking clothing).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb456ae-3f8a-4e5a-a61c-3219e1a557f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurveyOne:\n",
    "    def __init__(self, prolific_id, age, gender, height, hair_type, hair_color, has_tattoos,\n",
    "                 education, is_student, is_in_workforce, industry,\n",
    "                 hobbies, favorite_hobby, interests, favorite_interest, music_genre, frequent_locations,\n",
    "                 bar_day_of_week, bar_time_of_day, bar_group_size, bar_clothing,\n",
    "                 restaurant_day_of_week, restaurant_time_of_day, restaurant_group_size, restaurant_clothing,\n",
    "                 university_day_of_week, university_time_of_day, university_group_size, university_clothing,\n",
    "                 workplace_day_of_week, workplace_time_of_day, workplace_group_size, workplace_clothing,\n",
    "                 community_day_of_week, community_time_of_day, community_group_size, community_clothing,\n",
    "                 cafe_day_of_week, cafe_time_of_day, cafe_group_size, cafe_clothing,\n",
    "                 attraction_day_of_week, attraction_time_of_day, attraction_group_size, attraction_clothing,\n",
    "                 outdoor_day_of_week, outdoor_time_of_day, outdoor_group_size, outdoor_clothing,\n",
    "                 gym_day_of_week, gym_time_of_day, gym_group_size, gym_clothing,\n",
    "                 personality, listen_or_speak, social_media, favorite_social_media, music_listen_time):\n",
    "\n",
    "        self.prolific_id = prolific_id\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.height = height\n",
    "        self.hair_type = hair_type\n",
    "        self.hair_color = hair_color\n",
    "        self.has_tattoos = has_tattoos\n",
    "        self.education = education\n",
    "        self.is_student = is_student\n",
    "        self.is_in_workforce = is_in_workforce\n",
    "        self.industry = industry\n",
    "        self.hobbies = hobbies.split(';')\n",
    "        self.favorite_hobby = favorite_hobby\n",
    "        self.interests = interests.split(';')\n",
    "        self.favorite_interest = favorite_interest\n",
    "        self.music_genre = music_genre\n",
    "        self.frequent_locations = frequent_locations.split(';')\n",
    "\n",
    "        # Location #1: Bar.\n",
    "        self.bar_day_of_week = bar_day_of_week\n",
    "        self.bar_time_of_day = bar_time_of_day\n",
    "        self.bar_group_size = bar_group_size\n",
    "        self.bar_clothing = bar_clothing.split(';')\n",
    "\n",
    "        # Location #2: Restaurant.\n",
    "        self.restaurant_day_of_week = restaurant_day_of_week\n",
    "        self.restaurant_time_of_day = restaurant_time_of_day\n",
    "        self.restaurant_group_size = restaurant_group_size\n",
    "        self.restaurant_clothing = restaurant_clothing.split(';')\n",
    "\n",
    "        # Location #3: University.\n",
    "        self.university_day_of_week = university_day_of_week\n",
    "        self.university_time_of_day = university_time_of_day\n",
    "        self.university_group_size = university_group_size\n",
    "        self.university_clothing = university_clothing.split(';')\n",
    "\n",
    "        # Location #4: Workplace.\n",
    "        self.workplace_day_of_week = workplace_day_of_week\n",
    "        self.workplace_time_of_day = workplace_time_of_day\n",
    "        self.workplace_group_size = workplace_group_size\n",
    "        self.workplace_clothing = workplace_clothing.split(';')\n",
    "\n",
    "        # Location #5: Community.\n",
    "        self.community_day_of_week = community_day_of_week\n",
    "        self.community_time_of_day = community_time_of_day\n",
    "        self.community_group_size = community_group_size\n",
    "        self.community_clothing = community_clothing.split(';')\n",
    "\n",
    "        # Location #6: Cafe.\n",
    "        self.cafe_day_of_week = cafe_day_of_week\n",
    "        self.cafe_time_of_day = cafe_time_of_day\n",
    "        self.cafe_group_size = cafe_group_size\n",
    "        self.cafe_clothing = cafe_clothing.split(';')\n",
    "\n",
    "        # Location #7: Attraction.\n",
    "        self.attraction_day_of_week = attraction_day_of_week\n",
    "        self.attraction_time_of_day = attraction_time_of_day\n",
    "        self.attraction_group_size = attraction_group_size\n",
    "        self.attraction_clothing = attraction_clothing.split(';')\n",
    "\n",
    "        # Location #8: Outdoor.\n",
    "        self.outdoor_day_of_week = outdoor_day_of_week\n",
    "        self.outdoor_time_of_day = outdoor_time_of_day\n",
    "        self.outdoor_group_size = outdoor_group_size\n",
    "        self.outdoor_clothing = outdoor_clothing.split(';')\n",
    "\n",
    "        # Location #9: Gym.\n",
    "        self.gym_day_of_week = gym_day_of_week\n",
    "        self.gym_time_of_day = gym_time_of_day\n",
    "        self.gym_group_size = gym_group_size\n",
    "        self.gym_clothing = gym_clothing.split(';')\n",
    "\n",
    "        self.personality = personality\n",
    "        self.listen_or_speak = listen_or_speak\n",
    "        self.social_media = social_media.split(';')\n",
    "        self.favorite_social_media = favorite_social_media\n",
    "        self.music_listen_time = music_listen_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5df1799-960e-49be-aee4-31de2eb7d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_one_results = []\n",
    "survey_one_results_dict = {}\n",
    "\n",
    "with open('survey1_twenty_initial_participants.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        result = SurveyOne(*row)\n",
    "        survey_one_results.append(result)\n",
    "        survey_one_results_dict[result.prolific_id] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878cd598-20a0-4345-b674-5ea757ec7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurveyTwo:\n",
    "    def __init__(self, timestamp, prolific_id, instructions, consent, decisions, explanations):\n",
    "        self.timestamp = timestamp\n",
    "        self.prolific_id = prolific_id\n",
    "        self.instructions = instructions\n",
    "        self.consent = consent\n",
    "        self.decisions = decisions  # List to store scenario decisions.\n",
    "        self.explanations = explanations  # List to store scenario explanations.\n",
    "\n",
    "# Function to read the CSV and create SurveyTwo objects\n",
    "def read_survey_two_data(csv_file):\n",
    "    survey_data = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "\n",
    "        for row in reader:\n",
    "            timestamp, prolific_id, instructions, consent = row[:4]\n",
    "\n",
    "            # Extract decisions and explanations, handling potential index errors.\n",
    "            decisions = [row[i] for i in range(4, len(row), 2) if i < len(row)][:-1]\n",
    "            explanations = [row[i] for i in range(5, len(row), 2) if i < len(row)]\n",
    "\n",
    "            survey_data.append(SurveyTwo(timestamp, prolific_id, instructions, consent, decisions, explanations))\n",
    "    return survey_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee7f1e5-686f-44fa-94a4-91381dacc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_two_results = read_survey_two_data('survey2_four_initial_bad_participants.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5661321-370f-4e2b-94b6-3a22026c8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_data_dict():\n",
    "    data = {\n",
    "        # Self (not dependent on location).  # *\n",
    "        'self_age': [],\n",
    "        'self_gender': [],\n",
    "        'self_height': [],\n",
    "        'self_hair_type': [],\n",
    "        'self_hair_color': [],\n",
    "        'self_tattoos': [],\n",
    "        'self_education': [],\n",
    "        'self_student': [],\n",
    "        'self_workforce': [],\n",
    "        'self_industry': [],\n",
    "        'self_hobby': [],  # Favorite hobby.\n",
    "        'self_interest': [],  # Favorite interest.\n",
    "        'self_music_genre': [],\n",
    "        'self_personality': [],\n",
    "        'self_conversational_intensity': [],\n",
    "        'self_social_media': [],  # Favorite social media.\n",
    "        'self_music_listen_time': [],\n",
    "\n",
    "        # Candidate (not dependent on location).  # *\n",
    "        'candidate_age': [],\n",
    "        'candidate_gender': [],\n",
    "        'candidate_height': [],\n",
    "        'candidate_hair_type': [],\n",
    "        'candidate_hair_color': [],\n",
    "        'candidate_tattoos': [],\n",
    "        'candidate_education': [],\n",
    "        'candidate_student': [],\n",
    "        'candidate_workforce': [],\n",
    "        'candidate_industry': [],\n",
    "        'candidate_hobby': [],  # Favorite hobby.\n",
    "        'candidate_interest': [],  # Favorite interest.\n",
    "        'candidate_music_genre': [],\n",
    "        'candidate_personality': [],\n",
    "        'candidate_conversational_intensity': [],\n",
    "        'candidate_social_media': [],  # Favorite social media.\n",
    "        'candidate_music_listen_time': [],\n",
    "\n",
    "        # Environment (non-deterministic).  # *\n",
    "        'location': [],\n",
    "        'weather': [],\n",
    "        'human_congestion_level': [],\n",
    "        'human_noise_level': [],\n",
    "        'non_human_noise_level': [],\n",
    "        'candidate_occluded': [],\n",
    "        'gaze_self_to_candidate': [],\n",
    "        'gaze_candidate_to_self': [],\n",
    "        'proximity': [],\n",
    "\n",
    "        # Environment (deterministic, dependent on location).  # *\n",
    "        'day_of_week': [],  # Based on candidate.\n",
    "        'time_of_day': [],  # Based on candidate.\n",
    "\n",
    "        # Self (dependent on location).  # *\n",
    "        'self_group_size': [],\n",
    "        'self_clothing_athletic': [],  # Deterministic.\n",
    "        'self_clothing_casual': [],  # Deterministic.\n",
    "        'self_clothing_trendy': [],  # Deterministic.\n",
    "        'self_clothing_formal': [],  # Deterministic.\n",
    "        'self_clothing_designer': [],  # Deterministic.\n",
    "        'self_clothing_hat': [],  # Deterministic.\n",
    "        'self_clothing_eyeglasses': [],  # Deterministic.\n",
    "        'self_clothing_sunglasses': [],  # Deterministic.\n",
    "        'self_clothing_necklace': [],  # Deterministic.\n",
    "        'self_clothing_luxury_watch': [],  # Deterministic.\n",
    "        'self_clothing_rings': [],  # Deterministic.\n",
    "        'self_clothing_earrings': [],  # Deterministic.\n",
    "        'self_clothing_smart_watch': [],  # Deterministic.\n",
    "\n",
    "        # Candidate (dependent on location).  # *\n",
    "        'candidate_group_size': [],\n",
    "        'candidate_clothing_athletic': [],  # Non-deterministic.\n",
    "        'candidate_clothing_casual': [],  # Non-deterministic.\n",
    "        'candidate_clothing_trendy': [],  # Non-deterministic.\n",
    "        'candidate_clothing_formal': [],  # Non-deterministic.\n",
    "        'candidate_clothing_designer': [],  # Non-deterministic.\n",
    "        'candidate_clothing_hat': [],  # Non-deterministic.\n",
    "        'candidate_clothing_eyeglasses': [],  # Non-deterministic.\n",
    "        'candidate_clothing_sunglasses': [],  # Non-deterministic.\n",
    "        'candidate_clothing_necklace': [],  # Non-deterministic.\n",
    "        'candidate_clothing_luxury_watch': [],  # Non-deterministic.\n",
    "        'candidate_clothing_rings': [],  # Non-deterministic.\n",
    "        'candidate_clothing_earrings': [],  # Non-deterministic.\n",
    "        'candidate_clothing_smart_watch': [],  # Non-deterministic.\n",
    "\n",
    "        # Output label.  # *\n",
    "        'self_decision': [],\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c777478-47d9-4bf3-9647-8ab64975d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioInfo:\n",
    "    def __init__(self,\n",
    "                 candidate_prolific_id,\n",
    "                 location,\n",
    "                 weather,\n",
    "                 human_congestion_level,\n",
    "                 human_noise_level,\n",
    "                 non_human_noise_level,\n",
    "                 candidate_occluded,\n",
    "                 gaze_self_to_candidate,\n",
    "                 gaze_candidate_to_self,\n",
    "                 proximity,\n",
    "                 candidate_clothing_athletic,\n",
    "                 candidate_clothing_casual,\n",
    "                 candidate_clothing_trendy,\n",
    "                 candidate_clothing_formal,\n",
    "                 candidate_clothing_designer,\n",
    "                 candidate_clothing_hat,\n",
    "                 candidate_clothing_eyeglasses,\n",
    "                 candidate_clothing_sunglasses,\n",
    "                 candidate_clothing_necklace,\n",
    "                 candidate_clothing_luxury_watch,\n",
    "                 candidate_clothing_rings,\n",
    "                 candidate_clothing_earrings,\n",
    "                 candidate_clothing_smart_watch):\n",
    "        self.candidate_prolific_id = candidate_prolific_id\n",
    "        self.location = location\n",
    "        self.weather = weather\n",
    "        self.human_congestion_level = human_congestion_level\n",
    "        self.human_noise_level = human_noise_level\n",
    "        self.non_human_noise_level = non_human_noise_level\n",
    "        self.candidate_occluded = candidate_occluded\n",
    "        self.gaze_self_to_candidate = gaze_self_to_candidate\n",
    "        self.gaze_candidate_to_self = gaze_candidate_to_self\n",
    "        self.proximity = proximity\n",
    "        self.candidate_clothing_athletic = candidate_clothing_athletic\n",
    "        self.candidate_clothing_casual = candidate_clothing_casual\n",
    "        self.candidate_clothing_trendy = candidate_clothing_trendy\n",
    "        self.candidate_clothing_formal = candidate_clothing_formal\n",
    "        self.candidate_clothing_designer = candidate_clothing_designer\n",
    "        self.candidate_clothing_hat = candidate_clothing_hat\n",
    "        self.candidate_clothing_eyeglasses = candidate_clothing_eyeglasses\n",
    "        self.candidate_clothing_sunglasses = candidate_clothing_sunglasses\n",
    "        self.candidate_clothing_necklace = candidate_clothing_necklace\n",
    "        self.candidate_clothing_luxury_watch = candidate_clothing_luxury_watch\n",
    "        self.candidate_clothing_rings = candidate_clothing_rings\n",
    "        self.candidate_clothing_earrings = candidate_clothing_earrings\n",
    "        self.candidate_clothing_smart_watch = candidate_clothing_smart_watch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc76c64-e26b-4cea-ae8c-1b8cf5edfd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_scenario_info(data, scenario_info):\n",
    "    data['location'].append(scenario_info.location)\n",
    "    data['weather'].append(scenario_info.weather)\n",
    "    data['human_congestion_level'].append(scenario_info.human_congestion_level)\n",
    "    data['human_noise_level'].append(scenario_info.human_noise_level)\n",
    "    data['non_human_noise_level'].append(scenario_info.non_human_noise_level)\n",
    "    data['candidate_occluded'].append(scenario_info.candidate_occluded)\n",
    "    data['gaze_self_to_candidate'].append(scenario_info.gaze_self_to_candidate)\n",
    "    data['gaze_candidate_to_self'].append(scenario_info.gaze_candidate_to_self)\n",
    "    data['proximity'].append(scenario_info.proximity)\n",
    "    data['candidate_clothing_athletic'].append(scenario_info.candidate_clothing_athletic)\n",
    "    data['candidate_clothing_casual'].append(scenario_info.candidate_clothing_casual)\n",
    "    data['candidate_clothing_trendy'].append(scenario_info.candidate_clothing_trendy)\n",
    "    data['candidate_clothing_formal'].append(scenario_info.candidate_clothing_formal)\n",
    "    data['candidate_clothing_designer'].append(scenario_info.candidate_clothing_designer)\n",
    "    data['candidate_clothing_hat'].append(scenario_info.candidate_clothing_hat)\n",
    "    data['candidate_clothing_eyeglasses'].append(scenario_info.candidate_clothing_eyeglasses)\n",
    "    data['candidate_clothing_sunglasses'].append(scenario_info.candidate_clothing_sunglasses)\n",
    "    data['candidate_clothing_necklace'].append(scenario_info.candidate_clothing_necklace)\n",
    "    data['candidate_clothing_luxury_watch'].append(scenario_info.candidate_clothing_luxury_watch)\n",
    "    data['candidate_clothing_rings'].append(scenario_info.candidate_clothing_rings)\n",
    "    data['candidate_clothing_earrings'].append(scenario_info.candidate_clothing_earrings)\n",
    "    data['candidate_clothing_smart_watch'].append(scenario_info.candidate_clothing_smart_watch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2e42a8-2040-410b-b70b-17860613d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_self_clothing(data, self_user, location):\n",
    "    data['self_clothing_athletic'].append(has_clothing('athletic clothes', self_user, location))\n",
    "    data['self_clothing_casual'].append(has_clothing('casual clothes', self_user, location))\n",
    "    data['self_clothing_trendy'].append(has_clothing('trendy clothes', self_user, location))\n",
    "    data['self_clothing_formal'].append(has_clothing('formal clothes', self_user, location))\n",
    "    data['self_clothing_designer'].append(has_clothing('designer clothes', self_user, location))\n",
    "    data['self_clothing_hat'].append(has_clothing('hat', self_user, location))\n",
    "    data['self_clothing_eyeglasses'].append(has_clothing('eyeglasses', self_user, location))\n",
    "    data['self_clothing_sunglasses'].append(has_clothing('sunglasses', self_user, location))\n",
    "    data['self_clothing_necklace'].append(has_clothing('necklace', self_user, location))\n",
    "    data['self_clothing_luxury_watch'].append(has_clothing('luxury watch', self_user, location))\n",
    "    data['self_clothing_rings'].append(has_clothing('rings', self_user, location))\n",
    "    data['self_clothing_earrings'].append(has_clothing('earrings', self_user, location))\n",
    "    data['self_clothing_smart_watch'].append(has_clothing('smart watch', self_user, location))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa02a4d-f886-4b55-b00f-8a2dfdb05eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(survey_one_results_dict, survey_two_results, scenario_info_list):\n",
    "    data = get_empty_data_dict()\n",
    "    for survey_two_result in survey_two_results:\n",
    "        self_prolific_id = survey_two_result.prolific_id\n",
    "        self_decisions = survey_two_result.decisions\n",
    "        if len(self_decisions) != len(scenario_info_list):\n",
    "            raise Exception(\"Length of self decisions does not match length of scenario info list.\")\n",
    "        for i in range(len(self_decisions)):\n",
    "            candidate_prolific_id = scenario_info_list[i].candidate_prolific_id\n",
    "\n",
    "            # Self (not dependent on location).\n",
    "            data['self_age'].append(int(survey_one_results_dict[self_prolific_id].age))\n",
    "            data['self_gender'].append(survey_one_results_dict[self_prolific_id].gender)\n",
    "            data['self_height'].append(feet_inches_to_inches(survey_one_results_dict[self_prolific_id].height))\n",
    "            data['self_hair_type'].append(survey_one_results_dict[self_prolific_id].hair_type)\n",
    "            data['self_hair_color'].append(survey_one_results_dict[self_prolific_id].hair_color)\n",
    "            data['self_tattoos'].append(survey_one_results_dict[self_prolific_id].has_tattoos)\n",
    "            data['self_education'].append(survey_one_results_dict[self_prolific_id].education)\n",
    "            data['self_student'].append(survey_one_results_dict[self_prolific_id].is_student)\n",
    "            data['self_workforce'].append(survey_one_results_dict[self_prolific_id].is_in_workforce)\n",
    "            data['self_industry'].append(survey_one_results_dict[self_prolific_id].industry)\n",
    "            data['self_hobby'].append(survey_one_results_dict[self_prolific_id].favorite_hobby)\n",
    "            data['self_interest'].append(survey_one_results_dict[self_prolific_id].favorite_interest)\n",
    "            data['self_music_genre'].append(survey_one_results_dict[self_prolific_id].music_genre)\n",
    "            data['self_personality'].append(survey_one_results_dict[self_prolific_id].personality)\n",
    "            data['self_conversational_intensity'].append(survey_one_results_dict[self_prolific_id].listen_or_speak)\n",
    "            data['self_social_media'].append(survey_one_results_dict[self_prolific_id].favorite_social_media)\n",
    "            data['self_music_listen_time'].append(survey_one_results_dict[self_prolific_id].music_listen_time)\n",
    "\n",
    "            # Candidate (not dependent on location).\n",
    "            data['candidate_age'].append(int(survey_one_results_dict[candidate_prolific_id].age))\n",
    "            data['candidate_gender'].append(survey_one_results_dict[candidate_prolific_id].gender)\n",
    "            data['candidate_height'].append(feet_inches_to_inches(survey_one_results_dict[candidate_prolific_id].height))\n",
    "            data['candidate_hair_type'].append(survey_one_results_dict[candidate_prolific_id].hair_type)\n",
    "            data['candidate_hair_color'].append(survey_one_results_dict[candidate_prolific_id].hair_color)\n",
    "            data['candidate_tattoos'].append(survey_one_results_dict[candidate_prolific_id].has_tattoos)\n",
    "            data['candidate_education'].append(survey_one_results_dict[candidate_prolific_id].education)\n",
    "            data['candidate_student'].append(survey_one_results_dict[candidate_prolific_id].is_student)\n",
    "            data['candidate_workforce'].append(survey_one_results_dict[candidate_prolific_id].is_in_workforce)\n",
    "            data['candidate_industry'].append(survey_one_results_dict[candidate_prolific_id].industry)\n",
    "            data['candidate_hobby'].append(survey_one_results_dict[candidate_prolific_id].favorite_hobby)\n",
    "            data['candidate_interest'].append(survey_one_results_dict[candidate_prolific_id].favorite_interest)\n",
    "            data['candidate_music_genre'].append(survey_one_results_dict[candidate_prolific_id].music_genre)\n",
    "            data['candidate_personality'].append(survey_one_results_dict[candidate_prolific_id].personality)\n",
    "            data['candidate_conversational_intensity'].append(survey_one_results_dict[candidate_prolific_id].listen_or_speak)\n",
    "            data['candidate_social_media'].append(survey_one_results_dict[candidate_prolific_id].favorite_social_media)\n",
    "            data['candidate_music_listen_time'].append(survey_one_results_dict[candidate_prolific_id].music_listen_time)\n",
    "\n",
    "            # Environment (non-deterministic) & Candidate clothing (non-deterministic).\n",
    "            append_scenario_info(data, scenario_info_list[i])\n",
    "\n",
    "            # Environment (deterministic, dependent on location). -- Based on candidate.\n",
    "            day_of_week, time_of_day, candidate_group_size = get_day_time_and_group_size(survey_one_results_dict[candidate_prolific_id], scenario_info_list[i].location)\n",
    "            data['day_of_week'].append(day_of_week)\n",
    "            data['time_of_day'].append(time_of_day)\n",
    "\n",
    "            # Self (dependent on location).\n",
    "            _, _, self_group_size = get_day_time_and_group_size(survey_one_results_dict[self_prolific_id], scenario_info_list[i].location)\n",
    "            data['self_group_size'].append(self_group_size)\n",
    "            append_self_clothing(data, survey_one_results_dict[self_prolific_id], scenario_info_list[i].location)\n",
    "\n",
    "            # Candidate (dependent on location).\n",
    "            data['candidate_group_size'].append(candidate_group_size)\n",
    "\n",
    "            # Output label.\n",
    "            data['self_decision'].append(self_decisions[i])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6109a4eb-a817-4352-893b-3096322b6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_info_1 = ScenarioInfo('5e78e53a0b2d8247350c1c86',\n",
    "                               'Sit-down restaurant',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_2 = ScenarioInfo('60dd16a6d16ec5f253b2e29e',\n",
    "                               'Cafe / Coffee shop',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_3 = ScenarioInfo('5d68c88914867f000139f627',\n",
    "                               'Sit-down restaurant',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_4 = ScenarioInfo('6620e04a8b73f1ffd8692f03',\n",
    "                               'Gym',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_5 = ScenarioInfo('5f0a5a99dbbf721316f118e2',\n",
    "                               'Cafe / Coffee shop',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_6 = ScenarioInfo('660752ba689e8457ca3487cd',\n",
    "                               'Bar / Nightclub',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_7 = ScenarioInfo('637ea165e071484955b325f7',\n",
    "                               'Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_8 = ScenarioInfo('659711fa417392dfbe43d439',\n",
    "                               'Sit-down restaurant',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_9 = ScenarioInfo('5eb3935fd0e02317909c5f32',\n",
    "                               'Sit-down restaurant',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "scenario_info_10 = ScenarioInfo('6604ae923fe580e8b2e745f2',\n",
    "                               'Cafe / Coffee shop',\n",
    "                               'weather',\n",
    "                               'human_congestion_level',\n",
    "                               'human_noise_level',\n",
    "                               'non_human_noise_level',\n",
    "                               'candidate_occluded',\n",
    "                               'gaze_self_to_candidate',\n",
    "                               'gaze_candidate_to_self',\n",
    "                               'proximity',\n",
    "                               'candidate_clothing_athletic',\n",
    "                               'candidate_clothing_casual',\n",
    "                               'candidate_clothing_trendy',\n",
    "                               'candidate_clothing_formal',\n",
    "                               'candidate_clothing_designer',\n",
    "                               'candidate_clothing_hat',\n",
    "                               'candidate_clothing_eyeglasses',\n",
    "                               'candidate_clothing_sunglasses',\n",
    "                               'candidate_clothing_necklace',\n",
    "                               'candidate_clothing_luxury_watch',\n",
    "                               'candidate_clothing_rings',\n",
    "                               'candidate_clothing_earrings',\n",
    "                               'candidate_clothing_smart_watch')\n",
    "\n",
    "scenario_info_list = [scenario_info_1, scenario_info_2, scenario_info_3, scenario_info_4, scenario_info_5,\n",
    "                      scenario_info_6, scenario_info_7, scenario_info_8, scenario_info_9, scenario_info_10]\n",
    "\n",
    "dataset = create_dataset(survey_one_results_dict, survey_two_results, scenario_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584388bd-9ce1-4131-aa0b-fcb872d260bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_best_metrics_from_tuple(numbers_tuple, numbers_list, update_markers, update_string):\n",
    "    if len(numbers_tuple) != len(numbers_list) or len(numbers_tuple) != len(update_markers):\n",
    "        raise ValueError(\"All lists/tuple must have the same length\")\n",
    "\n",
    "    updated_list = []\n",
    "    updated_markers = []\n",
    "    for tuple_value, list_value, marker in zip(numbers_tuple, numbers_list, update_markers):\n",
    "        if tuple_value > list_value:\n",
    "            updated_list.append(tuple_value)\n",
    "            updated_markers.append(update_string)\n",
    "        else:\n",
    "            updated_list.append(list_value)\n",
    "            updated_markers.append(marker)  # Keep original marker\n",
    "\n",
    "    return updated_list, updated_markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5ba364f-f7ec-4dec-9973-0a065195a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cross_val():\n",
    "    df = pd.DataFrame(dataset)\n",
    "    \n",
    "    # Preprocessing for model using all features (includes MR, right-time, and user features).\n",
    "    X_mr = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "    y_mr = df['self_decision']\n",
    "    y_mr_accept_reject = y_mr.copy()\n",
    "    y_mr_accept_reject = y_mr_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_mr = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_mr_transformed = transformer_mr.fit_transform(X_mr)\n",
    "\n",
    "    # Preprocessing for model which excludes MR features but includes right-time-features and user features.\n",
    "    X_non_mr = df[['self_age', 'self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "            'day_of_week', 'time_of_day']]\n",
    "    y_non_mr = df['self_decision']\n",
    "    y_non_mr_accept_reject = y_non_mr.copy()\n",
    "    y_non_mr_accept_reject = y_non_mr_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_non_mr = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "            'day_of_week', 'time_of_day'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_non_mr_transformed = transformer_non_mr.fit_transform(X_non_mr)\n",
    "\n",
    "    # Preprocessing for model which excludes right-time features but includes MR and user features.\n",
    "    X_mr_user = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time',\n",
    "            'human_congestion_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_c lothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "    y_mr_user = df['self_decision']\n",
    "    y_mr_user_accept_reject = y_mr_user.copy()\n",
    "    y_mr_user_accept_reject = y_mr_user_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_mr_user = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time',\n",
    "            'human_congestion_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_mr_user_transformed = transformer_mr_user.fit_transform(X_mr_user)\n",
    "\n",
    "    # Preprocessing for model which only includes user features.\n",
    "    X_user = df[['self_age', 'self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time']]\n",
    "    y_user = df['self_decision']\n",
    "    y_user_accept_reject = y_user.copy()\n",
    "    y_user_accept_reject = y_user_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_user = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_user_transformed = transformer_user.fit_transform(X_user)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 500, 1000, 2000],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_meet_chat_reject_mr_metrics = [0] * 10\n",
    "    best_meet_chat_reject_mr_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_mr_metrics = [0] * 10\n",
    "    best_accept_reject_mr_files = [''] * 10\n",
    "\n",
    "    best_meet_chat_reject_non_mr_metrics = [0] * 10\n",
    "    best_meet_chat_reject_non_mr_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_non_mr_metrics = [0] * 10\n",
    "    best_accept_reject_non_mr_files = [''] * 10\n",
    "\n",
    "##################################################\n",
    "\n",
    "    best_meet_chat_reject_mr_user_metrics = [0] * 10\n",
    "    best_meet_chat_reject_mr_user_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_mr_user_metrics = [0] * 10\n",
    "    best_accept_reject_mr_user_files = [''] * 10\n",
    "\n",
    "    best_meet_chat_reject_user_metrics = [0] * 10\n",
    "    best_meet_chat_reject_user_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_user_metrics = [0] * 10\n",
    "    best_accept_reject_user_files = [''] * 10\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        filename = f\"model_results/rf_results_{timestamp}_{params}.txt\"\n",
    "    \n",
    "        with open(filename, 'w') as f:\n",
    "            print(f'Writing file: {filename}')\n",
    "            f.write(f\"Hyperparameters: {params}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for model using all features (includes MR, right-time, and user features).\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel using all features (includes MR, right-time, and user features):\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_mr_transformed):\n",
    "                X_train, X_test = X_mr_transformed[train_index], X_mr_transformed[test_index]\n",
    "                y_train, y_test = y_mr[train_index], y_mr[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_mr_accept_reject[train_index], y_mr_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (MR + right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_mr_metrics, best_meet_chat_reject_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_mr_metrics, best_meet_chat_reject_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_mr_files: {best_meet_chat_reject_mr_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (MR + right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_mr_metrics, best_accept_reject_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_mr_metrics, best_accept_reject_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_mr_files: {best_accept_reject_mr_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for model which excludes MR features but includes right-time-features and user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which excludes MR features but includes right-time-features and user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_non_mr_transformed):\n",
    "                X_train, X_test = X_non_mr_transformed[train_index], X_non_mr_transformed[test_index]\n",
    "                y_train, y_test = y_non_mr[train_index], y_non_mr[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_non_mr_accept_reject[train_index], y_non_mr_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average non-MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (non-MR, w/ right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_non_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_non_mr_metrics, best_meet_chat_reject_non_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_non_mr_metrics, best_meet_chat_reject_non_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_non_mr_files: {best_meet_chat_reject_non_mr_files}\\n\")\n",
    "\n",
    "            # Average non-MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (non-MR, w/ right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_non_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_non_mr_metrics, best_accept_reject_non_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_non_mr_metrics, best_accept_reject_non_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_non_mr_files: {best_accept_reject_non_mr_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for model which excludes right-time features but includes MR and user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which excludes right-time features but includes MR and user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_mr_user_transformed):\n",
    "                X_train, X_test = X_mr_user_transformed[train_index], X_mr_user_transformed[test_index]\n",
    "                y_train, y_test = y_mr_user[train_index], y_mr_user[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_mr_user_accept_reject[train_index], y_mr_user_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (MR + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_mr_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_mr_user_metrics, best_meet_chat_reject_mr_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_mr_user_metrics, best_meet_chat_reject_mr_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_mr_user_files: {best_meet_chat_reject_mr_user_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (MR + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_mr_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_mr_user_metrics, best_accept_reject_mr_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_mr_user_metrics, best_accept_reject_mr_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_mr_user_files: {best_accept_reject_mr_user_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for model which only includes user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which only includes user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_user_transformed):\n",
    "                X_train, X_test = X_user_transformed[train_index], X_user_transformed[test_index]\n",
    "                y_train, y_test = y_user[train_index], y_user[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_user_accept_reject[train_index], y_user_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_user_metrics, best_meet_chat_reject_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_user_metrics, best_meet_chat_reject_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_user_files: {best_meet_chat_reject_user_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_user_metrics, best_accept_reject_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_user_metrics, best_accept_reject_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_user_files: {best_accept_reject_user_files}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6789bac2-1bf0-4834-85a7-a36d6a4ac987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file: model_results/rf_results_20240424-002413_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}.txt\n",
      "Writing file: model_results/rf_results_20240424-002415_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}.txt\n",
      "Writing file: model_results/rf_results_20240424-002424_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}.txt\n",
      "Writing file: model_results/rf_results_20240424-002442_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 2000}.txt\n",
      "Writing file: model_results/rf_results_20240424-002518_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}.txt\n",
      "Writing file: model_results/rf_results_20240424-002520_{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_cross_val()\n",
      "Cell \u001b[0;32mIn[18], line 473\u001b[0m, in \u001b[0;36mrf_cross_val\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m y_train_accept_reject, y_test_accept_reject \u001b[38;5;241m=\u001b[39m y_user_accept_reject[train_index], y_user_accept_reject[test_index]\n\u001b[1;32m    472\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 473\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    474\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    476\u001b[0m rf_accept_reject \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:178\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 178\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# Need to validate separately here.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# csr.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1226\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmtrand\u001b[38;5;241m.\u001b[39m_rand\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(seed)\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState):\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:132\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_cross_val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3bffd-b11c-4592-b289-4259ff8db133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Preprocessing\n",
    "X = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "        'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "        'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "        'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "        'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "        'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "        'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "        'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "        'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "        'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "y = df['self_decision']\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "        'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "        'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "        'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "        'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "        'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "        'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "        'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "        'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "        'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_transformed = transformer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2252a0-2afe-4bb3-b2fc-98a49a8c2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "joblib.dump(rf_clf, 'saved_models/my_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be1777-a243-4b82-8216-061ea5b230d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('saved_models/my_model.joblib')\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a62ae0-ed8a-453e-9727-f3080e4c86d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
