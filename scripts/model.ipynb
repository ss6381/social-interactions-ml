{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63d9ac2-89bb-4e0e-b887-00073a18d911",
   "metadata": {
    "id": "c63d9ac2-89bb-4e0e-b887-00073a18d911"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import joblib\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88edf8f-bf97-4552-aced-9699f6b78329",
   "metadata": {
    "id": "e88edf8f-bf97-4552-aced-9699f6b78329"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597e86d5-1684-4fe6-9d02-6b454fdfd478",
   "metadata": {
    "id": "597e86d5-1684-4fe6-9d02-6b454fdfd478"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import sklearn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf25781-d454-4ef7-87fd-115c45a9cc34",
   "metadata": {
    "id": "fdf25781-d454-4ef7-87fd-115c45a9cc34"
   },
   "outputs": [],
   "source": [
    "def feet_inches_to_inches(string):\n",
    "    split = string.split('ft')\n",
    "    feet = split[0].strip()\n",
    "    inches = split[1].strip()\n",
    "    inches = inches.split('in')\n",
    "    inches = inches[0].strip()\n",
    "    return 12 * int(feet) + int(inches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614e2f3c-67a8-4cd9-bc21-8d6a9f57d29a",
   "metadata": {
    "id": "614e2f3c-67a8-4cd9-bc21-8d6a9f57d29a"
   },
   "outputs": [],
   "source": [
    "def get_day_time_and_group_size(user, location):\n",
    "    if location.endswith('.'):\n",
    "        location = location[:-1]  # Remove the period.\n",
    "    match location:\n",
    "        case \"Bar / Nightclub\":\n",
    "            return user.bar_day_of_week, user.bar_time_of_day, user.bar_group_size\n",
    "        case \"Sit-down restaurant\":\n",
    "            return user.restaurant_day_of_week, user.restaurant_time_of_day, user.restaurant_group_size\n",
    "        case \"University\":\n",
    "            return user.university_day_of_week, user.university_time_of_day, user.university_group_size\n",
    "        case \"School / University\":\n",
    "            return user.university_day_of_week, user.university_time_of_day, user.university_group_size\n",
    "        case \"Workplace\":\n",
    "            return user.workplace_day_of_week, user.workplace_time_of_day, user.workplace_group_size\n",
    "        case \"Community event (block-party, social club, hangout, potluck, etc.)\":\n",
    "            return user.community_day_of_week, user.community_time_of_day, user.community_group_size\n",
    "        case \"Cafe / Coffee shop\":\n",
    "            return user.cafe_day_of_week, user.cafe_time_of_day, user.cafe_group_size\n",
    "        case \"Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)\":\n",
    "            return user.attraction_day_of_week, user.attraction_time_of_day, user.attraction_group_size\n",
    "        case \"Outdoor activity (walking/hiking trail, biking, park, neighborhood, dog park, etc.)\":\n",
    "            return user.outdoor_day_of_week, user.outdoor_time_of_day, user.outdoor_group_size\n",
    "        case \"Gym\":\n",
    "            return user.gym_day_of_week, user.gym_time_of_day, user.gym_group_size\n",
    "        case _:\n",
    "            raise Exception(\"Invalid location.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2eb8d4-7ff2-428f-ba8a-72836df35af2",
   "metadata": {
    "id": "1a2eb8d4-7ff2-428f-ba8a-72836df35af2"
   },
   "outputs": [],
   "source": [
    "def clean_clothing_list(clothing_list):\n",
    "    result = []\n",
    "    for clothing in clothing_list:\n",
    "        cloth = clothing\n",
    "        if cloth.endswith('.'):\n",
    "            cloth = cloth[:-1]  # Remove the period.\n",
    "        cloth = cloth.lower()\n",
    "        result.append(cloth)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a4d03a-2279-4403-96bd-26f30625e85d",
   "metadata": {
    "id": "06a4d03a-2279-4403-96bd-26f30625e85d"
   },
   "outputs": [],
   "source": [
    "def has_clothing(clothing_str, user, location):\n",
    "    clothing_str = clothing_str.lower()\n",
    "    if clothing_str.endswith('.'):\n",
    "        clothing_str = clothing_str[:-1]  # Remove the period.\n",
    "    if clothing_str not in ['athletic clothes', 'casual clothes', 'trendy clothes', 'formal clothes', 'designer clothes', 'hat', 'eyeglasses', 'sunglasses', 'necklace', 'luxury watch', 'rings', 'earrings', 'smart watch']:\n",
    "        raise Exception(\"Invalid clothing.\")\n",
    "    if location.endswith('.'):\n",
    "        location = location[:-1]  # Remove the period.\n",
    "    match location:\n",
    "        case \"Bar / Nightclub\":\n",
    "            return clothing_str in clean_clothing_list(user.bar_clothing)\n",
    "        case \"Sit-down restaurant\":\n",
    "            return clothing_str in clean_clothing_list(user.restaurant_clothing)\n",
    "        case \"University\":\n",
    "            return clothing_str in clean_clothing_list(user.university_clothing)\n",
    "        case \"School / University\":\n",
    "            return clothing_str in clean_clothing_list(user.university_clothing)\n",
    "        case \"Workplace\":\n",
    "            return clothing_str in clean_clothing_list(user.workplace_clothing)\n",
    "        case \"Community event (block-party, social club, hangout, potluck, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.community_clothing)\n",
    "        case \"Cafe / Coffee shop\":\n",
    "            return clothing_str in clean_clothing_list(user.cafe_clothing)\n",
    "        case \"Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.attraction_clothing)\n",
    "        case \"Outdoor activity (walking/hiking trail, biking, park, neighborhood, dog park, etc.)\":\n",
    "            return clothing_str in clean_clothing_list(user.outdoor_clothing)\n",
    "        case \"Gym\":\n",
    "            return clothing_str in clean_clothing_list(user.gym_clothing)\n",
    "        case _:\n",
    "            raise Exception(\"Invalid location (when checking clothing).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb456ae-3f8a-4e5a-a61c-3219e1a557f4",
   "metadata": {
    "id": "fdb456ae-3f8a-4e5a-a61c-3219e1a557f4"
   },
   "outputs": [],
   "source": [
    "class SurveyOne:\n",
    "    def __init__(self, timestamp, prolific_id, instructions, consent, age,\n",
    "                 gender, height, hair_type, hair_color, has_tattoos,\n",
    "                 education, is_student, is_in_workforce, industry,\n",
    "                 hobbies, favorite_hobby, interests, favorite_interest, music_genre, frequent_locations,\n",
    "                 bar_day_of_week, bar_time_of_day, bar_group_size, bar_clothing,\n",
    "                 restaurant_day_of_week, restaurant_time_of_day, restaurant_group_size, restaurant_clothing,\n",
    "                 university_day_of_week, university_time_of_day, university_group_size, university_clothing,\n",
    "                 workplace_day_of_week, workplace_time_of_day, workplace_group_size, workplace_clothing,\n",
    "                 community_day_of_week, community_time_of_day, community_group_size, community_clothing,\n",
    "                 cafe_day_of_week, cafe_time_of_day, cafe_group_size, cafe_clothing,\n",
    "                 attraction_day_of_week, attraction_time_of_day, attraction_group_size, attraction_clothing,\n",
    "                 outdoor_day_of_week, outdoor_time_of_day, outdoor_group_size, outdoor_clothing,\n",
    "                 gym_day_of_week, gym_time_of_day, gym_group_size, gym_clothing,\n",
    "                 personality, listen_or_speak, social_media, favorite_social_media,\n",
    "                 interaction_frequency_preference, interaction_difficulty, interaction_method_preference,\n",
    "                 shared_personal_info, music_listen_time, open_to_music_connection, notification_usefulness,\n",
    "                 submit_option):\n",
    "\n",
    "        self.prolific_id = prolific_id\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.height = height\n",
    "        self.hair_type = hair_type\n",
    "        self.hair_color = hair_color\n",
    "        self.has_tattoos = has_tattoos\n",
    "        self.education = education\n",
    "        self.is_student = is_student\n",
    "        self.is_in_workforce = is_in_workforce\n",
    "        self.industry = industry\n",
    "        self.hobbies = hobbies.split(';')\n",
    "        self.favorite_hobby = favorite_hobby\n",
    "        self.interests = interests.split(';')\n",
    "        self.favorite_interest = favorite_interest\n",
    "        self.music_genre = music_genre\n",
    "        self.frequent_locations = frequent_locations.split(';')\n",
    "\n",
    "        # Location #1: Bar.\n",
    "        self.bar_day_of_week = bar_day_of_week\n",
    "        self.bar_time_of_day = bar_time_of_day\n",
    "        self.bar_group_size = bar_group_size\n",
    "        self.bar_clothing = bar_clothing.split(';')\n",
    "\n",
    "        # Location #2: Restaurant.\n",
    "        self.restaurant_day_of_week = restaurant_day_of_week\n",
    "        self.restaurant_time_of_day = restaurant_time_of_day\n",
    "        self.restaurant_group_size = restaurant_group_size\n",
    "        self.restaurant_clothing = restaurant_clothing.split(';')\n",
    "\n",
    "        # Location #3: University.\n",
    "        self.university_day_of_week = university_day_of_week\n",
    "        self.university_time_of_day = university_time_of_day\n",
    "        self.university_group_size = university_group_size\n",
    "        self.university_clothing = university_clothing.split(';')\n",
    "\n",
    "        # Location #4: Workplace.\n",
    "        self.workplace_day_of_week = workplace_day_of_week\n",
    "        self.workplace_time_of_day = workplace_time_of_day\n",
    "        self.workplace_group_size = workplace_group_size\n",
    "        self.workplace_clothing = workplace_clothing.split(';')\n",
    "\n",
    "        # Location #5: Community.\n",
    "        self.community_day_of_week = community_day_of_week\n",
    "        self.community_time_of_day = community_time_of_day\n",
    "        self.community_group_size = community_group_size\n",
    "        self.community_clothing = community_clothing.split(';')\n",
    "\n",
    "        # Location #6: Cafe.\n",
    "        self.cafe_day_of_week = cafe_day_of_week\n",
    "        self.cafe_time_of_day = cafe_time_of_day\n",
    "        self.cafe_group_size = cafe_group_size\n",
    "        self.cafe_clothing = cafe_clothing.split(';')\n",
    "\n",
    "        # Location #7: Attraction.\n",
    "        self.attraction_day_of_week = attraction_day_of_week\n",
    "        self.attraction_time_of_day = attraction_time_of_day\n",
    "        self.attraction_group_size = attraction_group_size\n",
    "        self.attraction_clothing = attraction_clothing.split(';')\n",
    "\n",
    "        # Location #8: Outdoor.\n",
    "        self.outdoor_day_of_week = outdoor_day_of_week\n",
    "        self.outdoor_time_of_day = outdoor_time_of_day\n",
    "        self.outdoor_group_size = outdoor_group_size\n",
    "        self.outdoor_clothing = outdoor_clothing.split(';')\n",
    "\n",
    "        # Location #9: Gym.\n",
    "        self.gym_day_of_week = gym_day_of_week\n",
    "        self.gym_time_of_day = gym_time_of_day\n",
    "        self.gym_group_size = gym_group_size\n",
    "        self.gym_clothing = gym_clothing.split(';')\n",
    "\n",
    "        self.personality = personality\n",
    "        self.listen_or_speak = listen_or_speak\n",
    "        self.social_media = social_media.split(';')\n",
    "        self.favorite_social_media = favorite_social_media\n",
    "        self.music_listen_time = music_listen_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5df1799-960e-49be-aee4-31de2eb7d05a",
   "metadata": {
    "id": "e5df1799-960e-49be-aee4-31de2eb7d05a"
   },
   "outputs": [],
   "source": [
    "def create_survey_one_results_dict(filepath):\n",
    "  survey_one_results = []\n",
    "  survey_one_results_dict = {}\n",
    "\n",
    "  with open(filepath, 'r') as file:\n",
    "      reader = csv.reader(file)\n",
    "      next(reader)\n",
    "      for row in reader:\n",
    "          result = SurveyOne(*row)\n",
    "          survey_one_results.append(result)\n",
    "          survey_one_results_dict[result.prolific_id] = result\n",
    "  return survey_one_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878cd598-20a0-4345-b674-5ea757ec7ea9",
   "metadata": {
    "id": "878cd598-20a0-4345-b674-5ea757ec7ea9"
   },
   "outputs": [],
   "source": [
    "class SurveyTwo:\n",
    "    def __init__(self, timestamp, prolific_id, instructions, consent, decisions, explanations):\n",
    "        self.timestamp = timestamp\n",
    "        self.prolific_id = prolific_id\n",
    "        self.instructions = instructions\n",
    "        self.consent = consent\n",
    "        self.decisions = decisions  # List to store scenario decisions.\n",
    "        self.explanations = explanations  # List to store scenario explanations.\n",
    "\n",
    "# Function to read the CSV and create SurveyTwo objects\n",
    "def read_survey_two_data(csv_file):\n",
    "    survey_data = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "\n",
    "        for row in reader:\n",
    "            timestamp, prolific_id, instructions, consent = row[:4]\n",
    "\n",
    "            # Extract decisions and explanations, handling potential index errors.\n",
    "            decisions = [row[i] for i in range(4, len(row), 2) if i < len(row)][:-1]\n",
    "            explanations = [row[i] for i in range(5, len(row), 2) if i < len(row)]\n",
    "\n",
    "            survey_data.append(SurveyTwo(timestamp, prolific_id, instructions, consent, decisions, explanations))\n",
    "    return survey_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5661321-370f-4e2b-94b6-3a22026c8b8b",
   "metadata": {
    "id": "b5661321-370f-4e2b-94b6-3a22026c8b8b"
   },
   "outputs": [],
   "source": [
    "def get_empty_data_dict():\n",
    "    data = {\n",
    "        # Self (not dependent on location).  # *\n",
    "        'self_age': [],\n",
    "        'self_gender': [],\n",
    "        'self_height': [],\n",
    "        'self_hair_type': [],\n",
    "        'self_hair_color': [],\n",
    "        'self_tattoos': [],\n",
    "        'self_education': [],\n",
    "        'self_student': [],\n",
    "        'self_workforce': [],\n",
    "        'self_industry': [],\n",
    "        'self_hobby': [],  # Favorite hobby.\n",
    "        'self_interest': [],  # Favorite interest.\n",
    "        'self_music_genre': [],\n",
    "        'self_personality': [],\n",
    "        'self_conversational_intensity': [],\n",
    "        'self_social_media': [],  # Favorite social media.\n",
    "        'self_music_listen_time': [],\n",
    "\n",
    "        # Candidate (not dependent on location).  # *\n",
    "        'candidate_age': [],\n",
    "        'candidate_gender': [],\n",
    "        'candidate_height': [],\n",
    "        'candidate_hair_type': [],\n",
    "        'candidate_hair_color': [],\n",
    "        'candidate_tattoos': [],\n",
    "        'candidate_education': [],\n",
    "        'candidate_student': [],\n",
    "        'candidate_workforce': [],\n",
    "        'candidate_industry': [],\n",
    "        'candidate_hobby': [],  # Favorite hobby.\n",
    "        'candidate_interest': [],  # Favorite interest.\n",
    "        'candidate_music_genre': [],\n",
    "        'candidate_personality': [],\n",
    "        'candidate_conversational_intensity': [],\n",
    "        'candidate_social_media': [],  # Favorite social media.\n",
    "        'candidate_music_listen_time': [],\n",
    "\n",
    "        # Environment (non-deterministic).  # *\n",
    "        'location': [],\n",
    "        'weather': [],\n",
    "        'human_congestion_level': [],\n",
    "        'human_noise_level': [],\n",
    "        'non_human_noise_level': [],\n",
    "        'candidate_occluded': [],\n",
    "        'gaze_self_to_candidate': [],\n",
    "        'gaze_candidate_to_self': [],\n",
    "        'proximity': [],\n",
    "\n",
    "        # Environment (deterministic, dependent on location).  # *\n",
    "        'day_of_week': [],  # Based on candidate.\n",
    "        'time_of_day': [],  # Based on candidate.\n",
    "\n",
    "        # Self (dependent on location).  # *\n",
    "        'self_group_size': [],\n",
    "        'self_clothing_athletic': [],  # Deterministic.\n",
    "        'self_clothing_casual': [],  # Deterministic.\n",
    "        'self_clothing_trendy': [],  # Deterministic.\n",
    "        'self_clothing_formal': [],  # Deterministic.\n",
    "        'self_clothing_designer': [],  # Deterministic.\n",
    "        'self_clothing_hat': [],  # Deterministic.\n",
    "        'self_clothing_eyeglasses': [],  # Deterministic.\n",
    "        'self_clothing_sunglasses': [],  # Deterministic.\n",
    "        'self_clothing_necklace': [],  # Deterministic.\n",
    "        'self_clothing_luxury_watch': [],  # Deterministic.\n",
    "        'self_clothing_rings': [],  # Deterministic.\n",
    "        'self_clothing_earrings': [],  # Deterministic.\n",
    "        'self_clothing_smart_watch': [],  # Deterministic.\n",
    "\n",
    "        # Candidate (dependent on location).  # *\n",
    "        'candidate_group_size': [],\n",
    "        'candidate_clothing_athletic': [],  # Non-deterministic.\n",
    "        'candidate_clothing_casual': [],  # Non-deterministic.\n",
    "        'candidate_clothing_trendy': [],  # Non-deterministic.\n",
    "        'candidate_clothing_formal': [],  # Non-deterministic.\n",
    "        'candidate_clothing_designer': [],  # Non-deterministic.\n",
    "        'candidate_clothing_hat': [],  # Non-deterministic.\n",
    "        'candidate_clothing_eyeglasses': [],  # Non-deterministic.\n",
    "        'candidate_clothing_sunglasses': [],  # Non-deterministic.\n",
    "        'candidate_clothing_necklace': [],  # Non-deterministic.\n",
    "        'candidate_clothing_luxury_watch': [],  # Non-deterministic.\n",
    "        'candidate_clothing_rings': [],  # Non-deterministic.\n",
    "        'candidate_clothing_earrings': [],  # Non-deterministic.\n",
    "        'candidate_clothing_smart_watch': [],  # Non-deterministic.\n",
    "\n",
    "        # Output label.  # *\n",
    "        'self_decision': [],\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c777478-47d9-4bf3-9647-8ab64975d5c1",
   "metadata": {
    "id": "9c777478-47d9-4bf3-9647-8ab64975d5c1"
   },
   "outputs": [],
   "source": [
    "class ScenarioInfo:\n",
    "    def __init__(self,\n",
    "                 scenario_id,\n",
    "                 candidate_prolific_id,\n",
    "                 location,\n",
    "                 weather,\n",
    "                 human_congestion_level,\n",
    "                 human_noise_level,\n",
    "                 non_human_noise_level,\n",
    "                 candidate_occluded,\n",
    "                 gaze_self_to_candidate,\n",
    "                 gaze_candidate_to_self,\n",
    "                 proximity,\n",
    "                 candidate_clothing_athletic,\n",
    "                 candidate_clothing_casual,\n",
    "                 candidate_clothing_trendy,\n",
    "                 candidate_clothing_formal,\n",
    "                 candidate_clothing_designer,\n",
    "                 candidate_clothing_hat,\n",
    "                 candidate_clothing_eyeglasses,\n",
    "                 candidate_clothing_sunglasses,\n",
    "                 candidate_clothing_necklace,\n",
    "                 candidate_clothing_luxury_watch,\n",
    "                 candidate_clothing_rings,\n",
    "                 candidate_clothing_earrings,\n",
    "                 candidate_clothing_smart_watch):\n",
    "        self.scenario_id = scenario_id\n",
    "        self.candidate_prolific_id = candidate_prolific_id\n",
    "        self.location = location\n",
    "        self.weather = weather\n",
    "        self.human_congestion_level = human_congestion_level\n",
    "        self.human_noise_level = human_noise_level\n",
    "        self.non_human_noise_level = non_human_noise_level\n",
    "        self.candidate_occluded = candidate_occluded\n",
    "        self.gaze_self_to_candidate = gaze_self_to_candidate\n",
    "        self.gaze_candidate_to_self = gaze_candidate_to_self\n",
    "        self.proximity = proximity\n",
    "        self.candidate_clothing_athletic = candidate_clothing_athletic\n",
    "        self.candidate_clothing_casual = candidate_clothing_casual\n",
    "        self.candidate_clothing_trendy = candidate_clothing_trendy\n",
    "        self.candidate_clothing_formal = candidate_clothing_formal\n",
    "        self.candidate_clothing_designer = candidate_clothing_designer\n",
    "        self.candidate_clothing_hat = candidate_clothing_hat\n",
    "        self.candidate_clothing_eyeglasses = candidate_clothing_eyeglasses\n",
    "        self.candidate_clothing_sunglasses = candidate_clothing_sunglasses\n",
    "        self.candidate_clothing_necklace = candidate_clothing_necklace\n",
    "        self.candidate_clothing_luxury_watch = candidate_clothing_luxury_watch\n",
    "        self.candidate_clothing_rings = candidate_clothing_rings\n",
    "        self.candidate_clothing_earrings = candidate_clothing_earrings\n",
    "        self.candidate_clothing_smart_watch = candidate_clothing_smart_watch\n",
    "\n",
    "    def print(self):\n",
    "      print(\"candidate_prolific_id:\", self.candidate_prolific_id)\n",
    "      print(\"location:\", self.location)\n",
    "      print(\"weather:\", self.weather)\n",
    "      print(\"human_congestion_level:\", self.human_congestion_level)\n",
    "      print(\"human_noise_level:\", self.human_noise_level)\n",
    "      print(\"non_human_noise_level:\", self.non_human_noise_level)\n",
    "      print(\"candidate_occluded:\", self.candidate_occluded)\n",
    "      print(\"gaze_self_to_candidate:\", self.gaze_self_to_candidate)\n",
    "      print(\"gaze_candidate_to_self:\", self.gaze_candidate_to_self)\n",
    "      print(\"proximity:\", self.proximity)\n",
    "      print(\"candidate_clothing_athletic:\", self.candidate_clothing_athletic)\n",
    "      print(\"candidate_clothing_casual:\", self.candidate_clothing_casual)\n",
    "      print(\"candidate_clothing_trendy:\", self.candidate_clothing_trendy)\n",
    "      print(\"candidate_clothing_formal:\", self.candidate_clothing_formal)\n",
    "      print(\"candidate_clothing_designer:\", self.candidate_clothing_designer)\n",
    "      print(\"candidate_clothing_hat:\", self.candidate_clothing_hat)\n",
    "      print(\"candidate_clothing_eyeglasses:\", self.candidate_clothing_eyeglasses)\n",
    "      print(\"candidate_clothing_sunglasses:\", self.candidate_clothing_sunglasses)\n",
    "      print(\"candidate_clothing_necklace:\", self.candidate_clothing_necklace)\n",
    "      print(\"candidate_clothing_luxury_watch:\", self.candidate_clothing_luxury_watch)\n",
    "      print(\"candidate_clothing_rings:\", self.candidate_clothing_rings)\n",
    "      print(\"candidate_clothing_earrings:\", self.candidate_clothing_earrings)\n",
    "      print(\"candidate_clothing_smart_watch:\", self.candidate_clothing_smart_watch)\n",
    "      print(\"\\n~~~~~~~~~~\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "y-xNYtB7ynba",
   "metadata": {
    "id": "y-xNYtB7ynba"
   },
   "outputs": [],
   "source": [
    "def read_scenario_info_list(filename):\n",
    "  scenario_info_list = []\n",
    "  with open(filename, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "      scenario_id, \\\n",
    "      candidate_prolific_id, \\\n",
    "      location, \\\n",
    "      weather, \\\n",
    "      human_congestion_level, \\\n",
    "      human_noise_level, \\\n",
    "      non_human_noise_level, \\\n",
    "      candidate_occluded, \\\n",
    "      gaze_self_to_candidate, \\\n",
    "      gaze_candidate_to_self, \\\n",
    "      proximity = row[:11]\n",
    "\n",
    "      candidate_clothing_athletic, \\\n",
    "      candidate_clothing_casual, \\\n",
    "      candidate_clothing_trendy, \\\n",
    "      candidate_clothing_formal, \\\n",
    "      candidate_clothing_designer, \\\n",
    "      candidate_clothing_hat, \\\n",
    "      candidate_clothing_eyeglasses, \\\n",
    "      candidate_clothing_sunglasses, \\\n",
    "      candidate_clothing_necklace, \\\n",
    "      candidate_clothing_luxury_watch, \\\n",
    "      candidate_clothing_rings, \\\n",
    "      candidate_clothing_earrings, \\\n",
    "      candidate_clothing_smart_watch = row[11:24]\n",
    "\n",
    "      scenario_info_list.append(\n",
    "        ScenarioInfo(\n",
    "          scenario_id,\n",
    "          candidate_prolific_id,\n",
    "          location,\n",
    "          weather,\n",
    "          human_congestion_level,\n",
    "          human_noise_level,\n",
    "          non_human_noise_level,\n",
    "          candidate_occluded,\n",
    "          gaze_self_to_candidate,\n",
    "          gaze_candidate_to_self,\n",
    "          proximity,\n",
    "          candidate_clothing_athletic,\n",
    "          candidate_clothing_casual,\n",
    "          candidate_clothing_trendy,\n",
    "          candidate_clothing_formal,\n",
    "          candidate_clothing_designer,\n",
    "          candidate_clothing_hat,\n",
    "          candidate_clothing_eyeglasses,\n",
    "          candidate_clothing_sunglasses,\n",
    "          candidate_clothing_necklace,\n",
    "          candidate_clothing_luxury_watch,\n",
    "          candidate_clothing_rings,\n",
    "          candidate_clothing_earrings,\n",
    "          candidate_clothing_smart_watch\n",
    "        )\n",
    "      )\n",
    "  return scenario_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc76c64-e26b-4cea-ae8c-1b8cf5edfd2e",
   "metadata": {
    "id": "5fc76c64-e26b-4cea-ae8c-1b8cf5edfd2e"
   },
   "outputs": [],
   "source": [
    "def append_scenario_info(data, scenario_info):\n",
    "    data['location'].append(scenario_info.location)\n",
    "    data['weather'].append(scenario_info.weather)\n",
    "    data['human_congestion_level'].append(scenario_info.human_congestion_level)\n",
    "    data['human_noise_level'].append(scenario_info.human_noise_level)\n",
    "    data['non_human_noise_level'].append(scenario_info.non_human_noise_level)\n",
    "    data['candidate_occluded'].append(scenario_info.candidate_occluded)\n",
    "    data['gaze_self_to_candidate'].append(scenario_info.gaze_self_to_candidate)\n",
    "    data['gaze_candidate_to_self'].append(scenario_info.gaze_candidate_to_self)\n",
    "    data['proximity'].append(scenario_info.proximity)\n",
    "    data['candidate_clothing_athletic'].append(scenario_info.candidate_clothing_athletic)\n",
    "    data['candidate_clothing_casual'].append(scenario_info.candidate_clothing_casual)\n",
    "    data['candidate_clothing_trendy'].append(scenario_info.candidate_clothing_trendy)\n",
    "    data['candidate_clothing_formal'].append(scenario_info.candidate_clothing_formal)\n",
    "    data['candidate_clothing_designer'].append(scenario_info.candidate_clothing_designer)\n",
    "    data['candidate_clothing_hat'].append(scenario_info.candidate_clothing_hat)\n",
    "    data['candidate_clothing_eyeglasses'].append(scenario_info.candidate_clothing_eyeglasses)\n",
    "    data['candidate_clothing_sunglasses'].append(scenario_info.candidate_clothing_sunglasses)\n",
    "    data['candidate_clothing_necklace'].append(scenario_info.candidate_clothing_necklace)\n",
    "    data['candidate_clothing_luxury_watch'].append(scenario_info.candidate_clothing_luxury_watch)\n",
    "    data['candidate_clothing_rings'].append(scenario_info.candidate_clothing_rings)\n",
    "    data['candidate_clothing_earrings'].append(scenario_info.candidate_clothing_earrings)\n",
    "    data['candidate_clothing_smart_watch'].append(scenario_info.candidate_clothing_smart_watch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b2e42a8-2040-410b-b70b-17860613d791",
   "metadata": {
    "id": "4b2e42a8-2040-410b-b70b-17860613d791"
   },
   "outputs": [],
   "source": [
    "def append_self_clothing(data, self_user, location):\n",
    "    data['self_clothing_athletic'].append(has_clothing('athletic clothes', self_user, location))\n",
    "    data['self_clothing_casual'].append(has_clothing('casual clothes', self_user, location))\n",
    "    data['self_clothing_trendy'].append(has_clothing('trendy clothes', self_user, location))\n",
    "    data['self_clothing_formal'].append(has_clothing('formal clothes', self_user, location))\n",
    "    data['self_clothing_designer'].append(has_clothing('designer clothes', self_user, location))\n",
    "    data['self_clothing_hat'].append(has_clothing('hat', self_user, location))\n",
    "    data['self_clothing_eyeglasses'].append(has_clothing('eyeglasses', self_user, location))\n",
    "    data['self_clothing_sunglasses'].append(has_clothing('sunglasses', self_user, location))\n",
    "    data['self_clothing_necklace'].append(has_clothing('necklace', self_user, location))\n",
    "    data['self_clothing_luxury_watch'].append(has_clothing('luxury watch', self_user, location))\n",
    "    data['self_clothing_rings'].append(has_clothing('rings', self_user, location))\n",
    "    data['self_clothing_earrings'].append(has_clothing('earrings', self_user, location))\n",
    "    data['self_clothing_smart_watch'].append(has_clothing('smart watch', self_user, location))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa02a4d-f886-4b55-b00f-8a2dfdb05eb8",
   "metadata": {
    "id": "6aa02a4d-f886-4b55-b00f-8a2dfdb05eb8"
   },
   "outputs": [],
   "source": [
    "def create_dataset(survey_one_results_dict, survey_two_results, scenario_info_list):\n",
    "    data = get_empty_data_dict()\n",
    "    for survey_two_result in survey_two_results:\n",
    "        self_prolific_id = survey_two_result.prolific_id\n",
    "        self_decisions = survey_two_result.decisions\n",
    "        if len(self_decisions) != len(scenario_info_list):\n",
    "            raise Exception(\"Length of self decisions does not match length of scenario info list.\")\n",
    "        for i in range(len(self_decisions)):\n",
    "            candidate_prolific_id = scenario_info_list[i].candidate_prolific_id\n",
    "\n",
    "            # Self (not dependent on location).\n",
    "            data['self_age'].append(int(survey_one_results_dict[self_prolific_id].age))\n",
    "            data['self_gender'].append(survey_one_results_dict[self_prolific_id].gender)\n",
    "            data['self_height'].append(feet_inches_to_inches(survey_one_results_dict[self_prolific_id].height))\n",
    "            data['self_hair_type'].append(survey_one_results_dict[self_prolific_id].hair_type)\n",
    "            data['self_hair_color'].append(survey_one_results_dict[self_prolific_id].hair_color)\n",
    "            data['self_tattoos'].append(survey_one_results_dict[self_prolific_id].has_tattoos)\n",
    "            data['self_education'].append(survey_one_results_dict[self_prolific_id].education)\n",
    "            data['self_student'].append(survey_one_results_dict[self_prolific_id].is_student)\n",
    "            data['self_workforce'].append(survey_one_results_dict[self_prolific_id].is_in_workforce)\n",
    "            data['self_industry'].append(survey_one_results_dict[self_prolific_id].industry)\n",
    "            data['self_hobby'].append(survey_one_results_dict[self_prolific_id].favorite_hobby)\n",
    "            data['self_interest'].append(survey_one_results_dict[self_prolific_id].favorite_interest)\n",
    "            data['self_music_genre'].append(survey_one_results_dict[self_prolific_id].music_genre)\n",
    "            data['self_personality'].append(survey_one_results_dict[self_prolific_id].personality)\n",
    "            data['self_conversational_intensity'].append(survey_one_results_dict[self_prolific_id].listen_or_speak)\n",
    "            data['self_social_media'].append(survey_one_results_dict[self_prolific_id].favorite_social_media)\n",
    "            data['self_music_listen_time'].append(survey_one_results_dict[self_prolific_id].music_listen_time)\n",
    "\n",
    "            # Candidate (not dependent on location).\n",
    "            data['candidate_age'].append(int(survey_one_results_dict[candidate_prolific_id].age))\n",
    "            data['candidate_gender'].append(survey_one_results_dict[candidate_prolific_id].gender)\n",
    "            data['candidate_height'].append(feet_inches_to_inches(survey_one_results_dict[candidate_prolific_id].height))\n",
    "            data['candidate_hair_type'].append(survey_one_results_dict[candidate_prolific_id].hair_type)\n",
    "            data['candidate_hair_color'].append(survey_one_results_dict[candidate_prolific_id].hair_color)\n",
    "            data['candidate_tattoos'].append(survey_one_results_dict[candidate_prolific_id].has_tattoos)\n",
    "            data['candidate_education'].append(survey_one_results_dict[candidate_prolific_id].education)\n",
    "            data['candidate_student'].append(survey_one_results_dict[candidate_prolific_id].is_student)\n",
    "            data['candidate_workforce'].append(survey_one_results_dict[candidate_prolific_id].is_in_workforce)\n",
    "            data['candidate_industry'].append(survey_one_results_dict[candidate_prolific_id].industry)\n",
    "            data['candidate_hobby'].append(survey_one_results_dict[candidate_prolific_id].favorite_hobby)\n",
    "            data['candidate_interest'].append(survey_one_results_dict[candidate_prolific_id].favorite_interest)\n",
    "            data['candidate_music_genre'].append(survey_one_results_dict[candidate_prolific_id].music_genre)\n",
    "            data['candidate_personality'].append(survey_one_results_dict[candidate_prolific_id].personality)\n",
    "            data['candidate_conversational_intensity'].append(survey_one_results_dict[candidate_prolific_id].listen_or_speak)\n",
    "            data['candidate_social_media'].append(survey_one_results_dict[candidate_prolific_id].favorite_social_media)\n",
    "            data['candidate_music_listen_time'].append(survey_one_results_dict[candidate_prolific_id].music_listen_time)\n",
    "\n",
    "            # Environment (non-deterministic) & Candidate clothing (non-deterministic).\n",
    "            append_scenario_info(data, scenario_info_list[i])\n",
    "\n",
    "            # Environment (deterministic, dependent on location). -- Based on candidate.\n",
    "            day_of_week, time_of_day, candidate_group_size = get_day_time_and_group_size(survey_one_results_dict[candidate_prolific_id], scenario_info_list[i].location)\n",
    "            data['day_of_week'].append(day_of_week)\n",
    "            data['time_of_day'].append(time_of_day)\n",
    "\n",
    "            # Self (dependent on location).\n",
    "            _, _, self_group_size = get_day_time_and_group_size(survey_one_results_dict[self_prolific_id], scenario_info_list[i].location)\n",
    "            data['self_group_size'].append(self_group_size)\n",
    "            append_self_clothing(data, survey_one_results_dict[self_prolific_id], scenario_info_list[i].location)\n",
    "\n",
    "            # Candidate (dependent on location).\n",
    "            data['candidate_group_size'].append(candidate_group_size)\n",
    "\n",
    "            # Output label.\n",
    "            data['self_decision'].append(self_decisions[i])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "SgwpzrofGVuS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgwpzrofGVuS",
    "outputId": "21aa5a18-3c0d-4ecf-e776-ea2c158862ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 74)\n",
      "(122, 74)\n",
      "(192, 74)\n",
      "74, 6\n",
      "(198, 74)\n"
     ]
    }
   ],
   "source": [
    "survey_one_data_filepath = '../data/users/[Final] [Part 1] Social Interactions Study (Responses) - '\n",
    "survey_two_data_filepath = '../data/decisions/[Final] [Part 2] Social Interactions Study (Responses) - '\n",
    "scenario_data_filepath = '../data/scenarios/[Final] [Scenarios] Social Interactions Study - '\n",
    "\n",
    "survey_one_results_dict_v1 = create_survey_one_results_dict(survey_one_data_filepath + 'v1.csv')\n",
    "survey_two_results_v1_10 = read_survey_two_data(survey_two_data_filepath + 'v1 (10 participants).csv')\n",
    "scenario_info_list_v1_10 = read_scenario_info_list(scenario_data_filepath + 'v1 (10 participants).csv')\n",
    "dataset = create_dataset(survey_one_results_dict_v1, survey_two_results_v1_10, scenario_info_list_v1_10)\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.shape)\n",
    "\n",
    "survey_two_results_v1_7 = read_survey_two_data(survey_two_data_filepath + 'v1 (7 participants).csv')\n",
    "scenario_info_list_v1_7 = read_scenario_info_list(scenario_data_filepath + 'v1 (7 participants).csv')\n",
    "dataset = create_dataset(survey_one_results_dict_v1, survey_two_results_v1_7, scenario_info_list_v1_7)\n",
    "df = pd.concat([df, pd.DataFrame(dataset, columns=df.columns)], ignore_index=True)\n",
    "print(df.shape)\n",
    "\n",
    "survey_one_results_dict_v2 = create_survey_one_results_dict(survey_one_data_filepath + 'v2.csv')\n",
    "survey_two_results_v2_10 = read_survey_two_data(survey_two_data_filepath + 'v2 (10 participants).csv')\n",
    "scenario_info_list_v2_10 = read_scenario_info_list(scenario_data_filepath + 'v2 (10 participants).csv')\n",
    "dataset = create_dataset(survey_one_results_dict_v2, survey_two_results_v2_10, scenario_info_list_v2_10)\n",
    "df = pd.concat([df, pd.DataFrame(dataset, columns=df.columns)], ignore_index=True)\n",
    "print(df.shape)\n",
    "\n",
    "survey_two_results_v2_6 = read_survey_two_data(survey_two_data_filepath + 'v2 (6 participants).csv')\n",
    "scenario_info_list_v2_6 = read_scenario_info_list(scenario_data_filepath + 'v2 (6 participants).csv')\n",
    "dataset = create_dataset(survey_one_results_dict_v2, survey_two_results_v2_6, scenario_info_list_v2_6)\n",
    "df = pd.concat([df, pd.DataFrame(dataset, columns=df.columns)], ignore_index=True)\n",
    "\n",
    "print(str(len(dataset)) + \",\", str(len(dataset['self_age'])))\n",
    "print(df.shape)\n",
    "# df.to_csv('../data/full_data_' + str(datetime.now()) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "PnaSeOOUIfVZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnaSeOOUIfVZ",
    "outputId": "e5fc125f-8b2b-4829-dbb3-218a6de80f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Reject': 88, 'Meet (in-person)': 57, 'Chat (via instant messaging)': 53})\n",
      "Counter({'Sit-down restaurant': 67, 'Cafe / Coffee shop': 31, 'Bar / Nightclub': 27, 'Gym': 21, 'Outdoor activity (walking/hiking trail, biking, park, neighborhood, dog park, etc.)': 21, 'School / University': 14, 'Workplace': 9, 'Attraction (museum, concert, movie theater, shopping mall, amusement park, etc.)': 8})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(collections.Counter(df['self_decision']))\n",
    "print(collections.Counter(df['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "OqOI1HQnKxCr",
   "metadata": {
    "id": "OqOI1HQnKxCr"
   },
   "outputs": [],
   "source": [
    "# Preprocessing for model using all features (includes MR and right-time features).\n",
    "X_mr = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "        'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "        'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "        'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "        'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "        'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "        'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "        'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "        'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "        'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "X_mr.to_csv('saved_models/X_combination_df.csv', index=False)\n",
    "y_mr = df['self_decision']\n",
    "transformer_mr = ColumnTransformer(\n",
    "    transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "        'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "        'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "        'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "        'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "        'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "        'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "        'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "        'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "        'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X_mr_transformed = transformer_mr.fit_transform(X_mr)\n",
    "\n",
    "# Preprocessing for model which excludes MR features but includes right-time-features.\n",
    "X_non_mr = df[['self_age', 'self_gender',\n",
    "        'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender',\n",
    "        'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "        'day_of_week', 'time_of_day']]\n",
    "X_non_mr.to_csv('saved_models/X_right_time_df.csv', index=False)\n",
    "y_non_mr = df['self_decision']\n",
    "transformer_non_mr = ColumnTransformer(\n",
    "    transformers=[('onehot', OneHotEncoder(), ['self_gender',\n",
    "        'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "        'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "        'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "        'candidate_education', 'candidate_student',\n",
    "        'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "        'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "        'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "        'day_of_week', 'time_of_day'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X_non_mr_transformed = transformer_non_mr.fit_transform(X_non_mr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5Wypspg-ao0o",
   "metadata": {
    "id": "5Wypspg-ao0o"
   },
   "outputs": [],
   "source": [
    "def update_best_metrics_from_tuple(numbers_tuple, numbers_list, update_markers, update_string):\n",
    "    if len(numbers_tuple) != len(numbers_list) or len(numbers_tuple) != len(update_markers):\n",
    "        raise ValueError(\"All lists/tuple must have the same length\")\n",
    "\n",
    "    updated_list = []\n",
    "    updated_markers = []\n",
    "    for tuple_value, list_value, marker in zip(numbers_tuple, numbers_list, update_markers):\n",
    "        if tuple_value > list_value:\n",
    "            updated_list.append(tuple_value)\n",
    "            updated_markers.append(update_string)\n",
    "        else:\n",
    "            updated_list.append(list_value)\n",
    "            updated_markers.append(marker)  # Keep original marker\n",
    "\n",
    "    return updated_list, updated_markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ClYJSA2y5kWe",
   "metadata": {
    "id": "ClYJSA2y5kWe"
   },
   "outputs": [],
   "source": [
    "def rf_cross_val():\n",
    "    df = pd.DataFrame(dataset)\n",
    "    \n",
    "    # Preprocessing for model using all features (includes MR, right-time, and user features).\n",
    "    X_mr = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "    y_mr = df['self_decision']\n",
    "    y_mr_accept_reject = y_mr.copy()\n",
    "    y_mr_accept_reject = y_mr_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_mr = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_congestion_level', 'human_noise_level', 'non_human_noise_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity', 'day_of_week', 'time_of_day',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_mr_transformed = transformer_mr.fit_transform(X_mr)\n",
    "\n",
    "    # Preprocessing for model which excludes MR features but includes right-time-features and user features.\n",
    "    X_non_mr = df[['self_age', 'self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "            'day_of_week', 'time_of_day']]\n",
    "    y_non_mr = df['self_decision']\n",
    "    y_non_mr_accept_reject = y_non_mr.copy()\n",
    "    y_non_mr_accept_reject = y_non_mr_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_non_mr = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time', 'location',\n",
    "            'weather', 'human_noise_level', 'non_human_noise_level',\n",
    "            'day_of_week', 'time_of_day'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_non_mr_transformed = transformer_non_mr.fit_transform(X_non_mr)\n",
    "\n",
    "    # Preprocessing for model which excludes right-time features but includes MR and user features.\n",
    "    X_mr_user = df[['self_age', 'self_gender', 'self_height', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender', 'candidate_height',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time',\n",
    "            'human_congestion_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch']]\n",
    "    y_mr_user = df['self_decision']\n",
    "    y_mr_user_accept_reject = y_mr_user.copy()\n",
    "    y_mr_user_accept_reject = y_mr_user_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_mr_user = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender', 'self_hair_type', 'self_hair_color',\n",
    "            'self_tattoos', 'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality', 'self_conversational_intensity',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_hair_type', 'candidate_hair_color', 'candidate_tattoos', 'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_conversational_intensity', 'candidate_social_media', 'candidate_music_listen_time',\n",
    "            'human_congestion_level', 'candidate_occluded',\n",
    "            'gaze_self_to_candidate', 'gaze_candidate_to_self', 'proximity',\n",
    "            'self_group_size', 'self_clothing_athletic', 'self_clothing_casual', 'self_clothing_trendy', 'self_clothing_formal',\n",
    "            'self_clothing_designer', 'self_clothing_hat', 'self_clothing_eyeglasses', 'self_clothing_sunglasses', 'self_clothing_necklace',\n",
    "            'self_clothing_luxury_watch', 'self_clothing_rings', 'self_clothing_earrings', 'self_clothing_smart_watch', 'candidate_group_size',\n",
    "            'candidate_clothing_athletic', 'candidate_clothing_casual', 'candidate_clothing_trendy', 'candidate_clothing_formal', 'candidate_clothing_designer',\n",
    "            'candidate_clothing_hat', 'candidate_clothing_eyeglasses', 'candidate_clothing_sunglasses', 'candidate_clothing_necklace', 'candidate_clothing_luxury_watch',\n",
    "            'candidate_clothing_rings', 'candidate_clothing_earrings', 'candidate_clothing_smart_watch'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_mr_user_transformed = transformer_mr_user.fit_transform(X_mr_user)\n",
    "\n",
    "    # Preprocessing for model which only includes user features.\n",
    "    X_user = df[['self_age', 'self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_age', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time']]\n",
    "    y_user = df['self_decision']\n",
    "    y_user_accept_reject = y_user.copy()\n",
    "    y_user_accept_reject = y_user_accept_reject.replace(['Meet (in-person)', 'Chat (via instant messaging)'], 'Accept')\n",
    "    transformer_user = ColumnTransformer(\n",
    "        transformers=[('onehot', OneHotEncoder(), ['self_gender',\n",
    "            'self_education', 'self_student', 'self_workforce', 'self_industry',\n",
    "            'self_hobby', 'self_interest', 'self_music_genre', 'self_personality',\n",
    "            'self_social_media', 'self_music_listen_time', 'candidate_gender',\n",
    "            'candidate_education', 'candidate_student',\n",
    "            'candidate_workforce', 'candidate_industry', 'candidate_hobby', 'candidate_interest', 'candidate_music_genre',\n",
    "            'candidate_personality', 'candidate_social_media', 'candidate_music_listen_time'])],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_user_transformed = transformer_user.fit_transform(X_user)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 500, 1000, 2000],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_meet_chat_reject_mr_metrics = [0] * 10\n",
    "    best_meet_chat_reject_mr_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_mr_metrics = [0] * 10\n",
    "    best_accept_reject_mr_files = [''] * 10\n",
    "\n",
    "    best_meet_chat_reject_non_mr_metrics = [0] * 10\n",
    "    best_meet_chat_reject_non_mr_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_non_mr_metrics = [0] * 10\n",
    "    best_accept_reject_non_mr_files = [''] * 10\n",
    "\n",
    "##################################################\n",
    "\n",
    "    best_meet_chat_reject_mr_user_metrics = [0] * 10\n",
    "    best_meet_chat_reject_mr_user_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_mr_user_metrics = [0] * 10\n",
    "    best_accept_reject_mr_user_files = [''] * 10\n",
    "\n",
    "    best_meet_chat_reject_user_metrics = [0] * 10\n",
    "    best_meet_chat_reject_user_files = [''] * 10\n",
    "\n",
    "    best_accept_reject_user_metrics = [0] * 10\n",
    "    best_accept_reject_user_files = [''] * 10\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        filename = f\"model_results/rf_results_{timestamp}_{params}.txt\"\n",
    "    \n",
    "        with open(filename, 'w') as f:\n",
    "            print(f'Writing file: {filename}')\n",
    "            f.write(f\"Hyperparameters: {params}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for combination model: (includes MR, right-time, and user features).\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel using all features (includes MR, right-time, and user features):\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_mr_transformed):\n",
    "                X_train, X_test = X_mr_transformed[train_index], X_mr_transformed[test_index]\n",
    "                y_train, y_test = y_mr[train_index], y_mr[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_mr_accept_reject[train_index], y_mr_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (MR + right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_combination_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_mr_metrics, best_meet_chat_reject_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_mr_metrics, best_meet_chat_reject_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_mr_files: {best_meet_chat_reject_mr_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (MR + right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_combination_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_mr_metrics, best_accept_reject_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_mr_metrics, best_accept_reject_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_mr_files: {best_accept_reject_mr_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for model right-time model: includes right-time-features and user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which excludes MR features but includes right-time-features and user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_non_mr_transformed):\n",
    "                X_train, X_test = X_non_mr_transformed[train_index], X_non_mr_transformed[test_index]\n",
    "                y_train, y_test = y_non_mr[train_index], y_non_mr[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_non_mr_accept_reject[train_index], y_non_mr_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average non-MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (non-MR, w/ right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_right_time_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_non_mr_metrics, best_meet_chat_reject_non_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_non_mr_metrics, best_meet_chat_reject_non_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_non_mr_files: {best_meet_chat_reject_non_mr_files}\\n\")\n",
    "\n",
    "            # Average non-MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (non-MR, w/ right-time + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_right_time_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_non_mr_metrics, best_accept_reject_non_mr_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_non_mr_metrics, best_accept_reject_non_mr_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_non_mr_files: {best_accept_reject_non_mr_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for mixed reality model: includes MR and user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which excludes right-time features but includes MR and user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_mr_user_transformed):\n",
    "                X_train, X_test = X_mr_user_transformed[train_index], X_mr_user_transformed[test_index]\n",
    "                y_train, y_test = y_mr_user[train_index], y_mr_user[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_mr_user_accept_reject[train_index], y_mr_user_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (MR + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_mr_user_metrics, best_meet_chat_reject_mr_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_mr_user_metrics, best_meet_chat_reject_mr_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_mr_user_files: {best_meet_chat_reject_mr_user_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (MR + user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_mr_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_mr_user_metrics, best_accept_reject_mr_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_mr_user_metrics, best_accept_reject_mr_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_mr_user_files: {best_accept_reject_mr_user_files}\\n\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "            # Cross-validation loop for user model: includes user features.\n",
    "            f.write(f\"~~~~~~~~~~\\n\\nModel which only includes user features:\\n\")\n",
    "            fold_metrics = []\n",
    "            fold_metrics_accept_reject = []\n",
    "            for train_index, test_index in kf.split(X_user_transformed):\n",
    "                X_train, X_test = X_user_transformed[train_index], X_user_transformed[test_index]\n",
    "                y_train, y_test = y_user[train_index], y_user[test_index]\n",
    "                y_train_accept_reject, y_test_accept_reject = y_user_accept_reject[train_index], y_user_accept_reject[test_index]\n",
    "\n",
    "                rf = RandomForestClassifier(**params)\n",
    "                rf.fit(X_train, y_train)\n",
    "                y_pred = rf.predict(X_test)\n",
    "\n",
    "                rf_accept_reject = RandomForestClassifier(**params)\n",
    "                rf_accept_reject.fit(X_train, y_train_accept_reject)\n",
    "                y_pred_accept_reject = rf_accept_reject.predict(X_test)\n",
    "\n",
    "                # Calculate metrics (meet, chat, reject).\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_metrics.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (meet, chat, reject): {fold_metrics[-1]}\\n\")\n",
    "\n",
    "                # Calculate metrics (accept, reject).\n",
    "                accuracy = accuracy_score(y_test_accept_reject, y_pred_accept_reject)\n",
    "                precision_weighted = precision_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                precision_micro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                precision_macro = precision_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                recall_weighted = recall_score(y_test_accept_reject, y_pred_accept_reject, average='weighted', zero_division=0)\n",
    "                recall_micro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='micro', zero_division=0)\n",
    "                recall_macro = recall_score(y_test_accept_reject, y_pred_accept_reject, average='macro', zero_division=0)\n",
    "                f1_weighted = f1_score(y_test_accept_reject, y_pred_accept_reject, average='weighted')\n",
    "                f1_micro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='micro')\n",
    "                f1_macro = f1_score(y_test_accept_reject, y_pred_accept_reject, average='macro')\n",
    "\n",
    "                fold_metrics_accept_reject.append((accuracy,\n",
    "                                     precision_weighted, precision_micro, precision_macro,\n",
    "                                     recall_weighted, recall_micro, recall_macro,\n",
    "                                     f1_weighted, f1_micro, f1_macro))\n",
    "                f.write(f\"Fold metrics (accept, reject): {fold_metrics_accept_reject[-1]}\\n\")\n",
    "\n",
    "            # Average MR metrics (meet, chat, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [MEET, CHAT, REJECT] METRICS (user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/meet_chat_reject_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf, model_filename)\n",
    "            best_meet_chat_reject_user_metrics, best_meet_chat_reject_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_meet_chat_reject_user_metrics, best_meet_chat_reject_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_meet_chat_reject_user_files: {best_meet_chat_reject_user_files}\\n\")\n",
    "\n",
    "            # Average MR metrics (accept, reject).\n",
    "            avg_metrics = tuple(np.mean(fold_metrics_accept_reject, axis=0))\n",
    "            f.write(\"\\n~~~~~~~~~~\\nAVERAGE [ACCEPT, REJECT] METRICS (user)\\n~~~~~~~~~~\")\n",
    "            f.write(f\"\\nAvg metrics: {avg_metrics}\\n\")\n",
    "            f.write(f\"Avg accuracy: {avg_metrics[0]}\\n\")\n",
    "            f.write(f\"Avg precision (weighted): {avg_metrics[1]}\\n\")\n",
    "            f.write(f\"Avg precision (micro): {avg_metrics[2]}\\n\")\n",
    "            f.write(f\"Avg precision (macro): {avg_metrics[3]}\\n\")\n",
    "            f.write(f\"Avg recall (weighted): {avg_metrics[4]}\\n\")\n",
    "            f.write(f\"Avg recall (micro): {avg_metrics[5]}\\n\")\n",
    "            f.write(f\"Avg recall (macro): {avg_metrics[6]}\\n\")\n",
    "            f.write(f\"Avg F1 (weighted): {avg_metrics[7]}\\n\")\n",
    "            f.write(f\"Avg F1 (micro): {avg_metrics[8]}\\n\")\n",
    "            f.write(f\"Avg F1 (macro): {avg_metrics[9]}\\n\")\n",
    "            model_filename = f'saved_models/accept_reject_user_{timestamp}_{params}.joblib'\n",
    "            joblib.dump(rf_accept_reject, model_filename)\n",
    "            best_accept_reject_user_metrics, best_accept_reject_user_files = update_best_metrics_from_tuple(avg_metrics,\n",
    "                    best_accept_reject_user_metrics, best_accept_reject_user_files, model_filename)\n",
    "            f.write(f\"\\nbest_accept_reject_user_files: {best_accept_reject_user_files}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "kK_MnVBZBibh",
   "metadata": {
    "id": "kK_MnVBZBibh"
   },
   "outputs": [],
   "source": [
    "# uncomment this if you want to write the results for\n",
    "# the random forest models in cross val to a file.\n",
    "\n",
    "# rf_cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "LWxIPqyDK3HA",
   "metadata": {
    "id": "LWxIPqyDK3HA"
   },
   "outputs": [],
   "source": [
    "# Train-test split for MR model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mr_transformed, y_mr, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pF9IyYjhK7ME",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pF9IyYjhK7ME",
    "outputId": "e00db19a-1985-4fe3-cf15-384812273c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved_models/mr_model.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# joblib.dump(rf_clf, 'saved_models/combination_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "V9l1WEr2ga2j",
   "metadata": {
    "id": "V9l1WEr2ga2j"
   },
   "outputs": [],
   "source": [
    "# Train-test split for non-MR model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_mr_transformed, y_non_mr, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "-jCzSUmcgbJM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jCzSUmcgbJM",
    "outputId": "3abef8b3-6fc3-45b3-f7ff-fdba6a574fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/best_accept_reject_right_time_20240424-124130044290.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "joblib.dump(rf_clf, '../models/best_accept_reject_right_time_20240424-124130044290.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
